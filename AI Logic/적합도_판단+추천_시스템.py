# -*- coding: utf-8 -*-
"""
ì í•©ë„ íŒë‹¨ + ì¶”ì²œ ì‹œìŠ¤í…œ (FastAPI ë²„ì „)
ë¡œì§ì€ ì›ë³¸ ê·¸ëŒ€ë¡œ ìœ ì§€í•˜ê³ , ìš”ì²­/ì‘ë‹µ êµ¬ì¡°ë§Œ ë°±ì—”ë“œ ì—°ë™ìš©ìœ¼ë¡œ ë³€ê²½
"""

import pandas as pd
import math
import mysql.connector
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from openai import OpenAI
from sklearn.metrics.pairwise import cosine_similarity
import numpy as np

# ---------------------------------------------------------
# ğŸ”¹ FastAPI ì´ˆê¸°í™”
# ---------------------------------------------------------
app = FastAPI(title="ì í•©ë„ íŒë‹¨ + ì¶”ì²œ ì‹œìŠ¤í…œ API")

# ---------------------------------------------------------
# ğŸ”¹ OpenAI API Key
# ---------------------------------------------------------
client = OpenAI(api_key="YOUR_OPENAI_API_KEY")  # ğŸ‘ˆ í™˜ê²½ë³€ìˆ˜ë¡œ ëŒ€ì²´ ê¶Œì¥

# ---------------------------------------------------------
# ğŸ”¹ RDS ì—°ê²° ì„¤ì •
# ---------------------------------------------------------
RDS_HOST = "ewha-baekkot-ending.c5cq20gw2kei.ap-northeast-2.rds.amazonaws.com"
RDS_USER = "popo"
RDS_PW = "EWHA_ending25"

# ---------------------------------------------------------
# ğŸ”¹ ìš”ì²­ ë°”ë”” ì •ì˜
# ---------------------------------------------------------
class RequestBody(BaseModel):
    user_id: str
    product_name: str

# ---------------------------------------------------------
# ğŸ”¹ ìˆ«ì ë³€í™˜ ìœ í‹¸
# ---------------------------------------------------------
def num(x):
    try:
        return float(str(x).replace(",", "").replace("mg", "").replace("g", "").replace("kcal", "").strip())
    except:
        return None

def split_list(x):
    if x is None or (isinstance(x, float) and pd.isna(x)):
        return []
    return [t.strip() for t in str(x).replace(";", ",").split(",") if t.strip()]

# ---------------------------------------------------------
# ğŸ”¹ í—¬ìŠ¤ì»¨ë””ì…˜ ë£°
# ---------------------------------------------------------
health_condition_rules = {
    "ê³ í˜ˆì••": {"ë‚˜íŠ¸ë¥¨": "low"},
    "ë‹¹ë‡¨": {"ë‹¹ë¥˜": "low"},
    "ê°ëŸ‰": {"ì¹¼ë¡œë¦¬": "low"},
    "ê³ ì§€í˜ˆì¦": {"ì§€ë°©": "low", "í¬í™”ì§€ë°©": "low", "íŠ¸ëœìŠ¤ì§€ë°©": "low"},
    "ì‹¬í˜ˆê´€ì§ˆí™˜": {"ë‚˜íŠ¸ë¥¨": "low", "í¬í™”ì§€ë°©": "low", "ì½œë ˆìŠ¤í…Œë¡¤": "low"},
    "ì‹ ì¥ì§ˆí™˜": {"ë‚˜íŠ¸ë¥¨": "low", "ë‹¨ë°±ì§ˆ": "low"},
    "ê°„ì§ˆí™˜": {"ë‹¹ë¥˜": "low", "ì§€ë°©": "low"},
    "ê³¨ë‹¤ê³µì¦": {"ì¹¼ìŠ˜": "high", "ë‚˜íŠ¸ë¥¨": "low"},
    "ê³ ì½œë ˆìŠ¤í…Œë¡¤í˜ˆì¦": {"ì½œë ˆìŠ¤í…Œë¡¤": "low", "í¬í™”ì§€ë°©": "low"},
    "í†µí’": {"ë‹¨ë°±ì§ˆ": "low"},
}

# ---------------------------------------------------------
# ğŸ”¹ ì£¼ìš” ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸
# ---------------------------------------------------------
@app.post("/analyze")
def analyze(body: RequestBody):
    user_id = body.user_id
    product_name = body.product_name

    # âœ… 1. ì‚¬ìš©ì ì •ë³´ ë¶ˆëŸ¬ì˜¤ê¸°
    conn = mysql.connector.connect(host=RDS_HOST, user=RDS_USER, password=RDS_PW, database="user_info_db")
    user_df = pd.read_sql("SELECT user_id, allergies, medical_conditions FROM user_private WHERE user_id = %s",
                          conn, params=[user_id])
    conn.close()

    if user_df.empty:
        raise HTTPException(status_code=404, detail="ì‚¬ìš©ì ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    user_allergies = split_list(user_df.iloc[0]["allergies"])
    user_goals = split_list(user_df.iloc[0]["medical_conditions"])

    # âœ… 2. ì œí’ˆ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
    conn = mysql.connector.connect(host=RDS_HOST, user=RDS_USER, password=RDS_PW, database="product_db")
    df = pd.read_sql("SELECT * FROM ramen_db", conn)
    conn.close()

    df.columns = [c.strip().replace(" ", "") for c in df.columns]
    for col in df.columns:
        if any(unit in col for unit in ["mg", "g", "kcal"]):
            df[col] = df[col].apply(num)
    if "ê°œë³„ë‚´ìš©ëŸ‰" in df.columns:
        df["ê°œë³„ë‚´ìš©ëŸ‰"] = df["ê°œë³„ë‚´ìš©ëŸ‰"].apply(num)

    # âœ… 3. ê¸°ì¤€ ì œí’ˆ ì„ íƒ
    row = df[df["í’ˆëª…"] == product_name]
    if row.empty:
        raise HTTPException(status_code=404, detail=f"'{product_name}' ì œí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    row = row.iloc[0]

    # âœ… 4. ê±´ê°•ëª©í‘œ ë§¤í•‘
    target_map = {}
    for goal in user_goals:
        if goal in health_condition_rules:
            target_map.update(health_condition_rules[goal])
    if not target_map:
        target_map = {"ì¹¼ë¡œë¦¬": "low"}

    # âœ… 5. ì•Œë ˆë¥´ê¸° ì§ì ‘ ì²´í¬
    notice = str(row.get("ì•Œë ˆë¥´ê¸°", "")).lower()
    final = "ë¶€ì í•©" if any(a.lower() in notice for a in user_allergies) else "ì í•©"

    # âœ… 6. ì„±ë¶„ í‰ê°€
    def calc_per_100(df, key):
        df_valid = df.dropna(subset=["ê°œë³„ë‚´ìš©ëŸ‰"])
        vals = []
        for _, r in df_valid.iterrows():
            try:
                vals.append(float(r.get(key, 0)) / float(r.get("ê°œë³„ë‚´ìš©ëŸ‰", 100)) * 100)
            except:
                continue
        return sum(vals) / len(vals) if vals else None

    nutrition_results = []
    for key, direction in target_map.items():
        try:
            value = float(row.get(key, 0))
            total = float(row.get("ê°œë³„ë‚´ìš©ëŸ‰", 100))
            per_100 = value / total * 100
        except:
            per_100 = None

        avg_value = calc_per_100(df, key)
        if value == 0 or per_100 == 0:
            status = "ë¯¸í•¨ìœ "
        elif avg_value is None or per_100 is None:
            status = "ì •ë³´ë¶€ì¡±"
        else:
            diff_ratio = per_100 / avg_value if avg_value != 0 else None
            if diff_ratio is None:
                status = "ì •ë³´ë¶€ì¡±"
            elif diff_ratio > 1.1:
                status = "í‰ê· ë³´ë‹¤ ë†’ìŒ"
            elif diff_ratio < 0.9:
                status = "í‰ê· ë³´ë‹¤ ë‚®ìŒ"
            else:
                status = "í‰ê· ê³¼ ë¹„ìŠ·í•¨"

        nutrition_results.append({
            "ì„±ë¶„": key, "ê°’": per_100, "í‰ê· ": avg_value,
            "ë°©í–¥": direction, "í‰ê°€": status
        })

    # âœ… 7. ê°„ì ‘ ì•Œë ˆë¥´ê¸°
    indirect = row.get("ê°„ì ‘ì•Œë ˆë¥´ê¸°", None)
    warning_text = ""
    if indirect and not (isinstance(indirect, float) and math.isnan(indirect)):
        indirect_str = str(indirect).lower()
        for a in user_allergies:
            if a.lower() in indirect_str or indirect_str in ["o", "yes", "1", "true"]:
                warning_text = f"âš ï¸ '{a}' ê°„ì ‘ ì•Œë ˆë¥´ê¸° ì£¼ì˜"
                break

    # âœ… 8. OpenAI ì„¤ëª… ìƒì„±
    try:
        nutrition_summary = ", ".join([f"{n['ì„±ë¶„']}({n['í‰ê°€']}, {n['ë°©í–¥']})" for n in nutrition_results])
        prompt = f"""
ì‚¬ìš©ì ì¡°ê±´:
- ì•Œë ˆë¥´ê¸°: {', '.join(user_allergies) if user_allergies else 'ì—†ìŒ'}
- ê±´ê°•ëª©í‘œ: {', '.join(user_goals)}
- ì£¼ìš” í‰ê°€ ì„±ë¶„ ë° ë°©í–¥: {nutrition_summary}

ì œí’ˆëª…: {product_name}
ìµœì¢…íŒì •: {final}
ê²½ê³ ë¬¸êµ¬: {warning_text}
"""
        res = client.responses.create(model="gpt-4.1-mini", input=prompt, temperature=0.3)
        reason = res.output_text.strip()
    except Exception:
        reason = "(AI ì„¤ëª… ìƒì„± ì‹¤íŒ¨)"


    
# ---------------------------------------------------------
# ğŸ”¹ ì—¬ê¸°ì„œë¶€í„° ì¶”ì²œ ì‹œìŠ¤í…œ (XGBoostë§Œ)
# ---------------------------------------------------------

    
    # âœ… 9. ìœ ì‚¬ë„ ê¸°ë°˜ ì¶”ì²œ
    def has_allergy(row, allergy_list):
        text = str(row.get("ì•Œë ˆë¥´ê¸°", "")).lower()
        return any(a.lower() in text for a in allergy_list)

    pool_df = df[~df.apply(lambda r: has_allergy(r, user_allergies), axis=1)].copy()
    pool_df = pool_df[pool_df["í’ˆëª…"] != product_name].copy()

    raw_cols = ["ì—´ëŸ‰","ì¹¼ë¡œë¦¬","ë‚˜íŠ¸ë¥¨","ë‹¹ë¥˜","íƒ„ìˆ˜í™”ë¬¼","ì§€ë°©","ë‹¨ë°±ì§ˆ",
                "ì½œë ˆìŠ¤í…Œë¡¤","í¬í™”ì§€ë°©","íŠ¸ëœìŠ¤ì§€ë°©","ì¹¼ìŠ˜","ì¹´í˜ì¸"]
    nutr_cols = [c for c in raw_cols if c in df.columns]

    def to_per100_frame(x):
        out = {}
        total = float(x.get("ê°œë³„ë‚´ìš©ëŸ‰", 100)) or 100
        for c in nutr_cols:
            try:
                out[c] = float(x.get(c, np.nan)) / total * 100
            except:
                out[c] = np.nan
        return pd.Series(out)

    base_vec = to_per100_frame(row)
    pool_per100 = pool_df.apply(to_per100_frame, axis=1)
    fill_vals = pool_per100.median()
    pool_per100 = pool_per100.fillna(fill_vals)
    base_vec = base_vec.fillna(fill_vals)
    sim = cosine_similarity([base_vec.values], pool_per100.values)[0]
    pool_df = pool_df.assign(similarity=sim).sort_values("similarity", ascending=False)
    top6 = pool_df.head(6)["í’ˆëª…"].tolist()

    # âœ… ì‘ë‹µ ë°˜í™˜
    return {
        "ì œí’ˆëª…": product_name,
        "ìµœì¢…íŒì •": final,
        "AIì„¤ëª…": reason,
        "ê²½ê³ ": warning_text,
        "ì„±ë¶„ë¶„ì„": nutrition_results,
        "ì¶”ì²œì œí’ˆ": top6
    }
